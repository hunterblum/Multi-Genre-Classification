{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4 - Modeling\n",
    "\n",
    "This notebook will perform the splitting of data, training and testing the selected models, and identifying the final model to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from ast import literal_eval\n",
    "from scipy import sparse\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lyrics_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​betty</td>\n",
       "      <td>Betty, I won't make assumptions\\nAbout why you...</td>\n",
       "      <td>[country]</td>\n",
       "      <td>[betty, make, assumptions, switched, homeroom,...</td>\n",
       "      <td>betty make assumptions switched homeroom think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Denver</td>\n",
       "      <td>Take Me Home, Country Roads</td>\n",
       "      <td>Almost Heaven, West Virginia\\nBlue Ridge Mount...</td>\n",
       "      <td>[country]</td>\n",
       "      <td>[almost, heaven, west, virginia, blue, ridge, ...</td>\n",
       "      <td>almost heaven west virginia blue ridge mountai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Feeling Whitney</td>\n",
       "      <td>I've been looking for someone...\\nOoh, ooh, oo...</td>\n",
       "      <td>[country]</td>\n",
       "      <td>[looking, someone, ooh, ooh, ooh, ooh, ooh, oo...</td>\n",
       "      <td>looking someone ooh ooh ooh ooh ooh oohooh ooh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cam</td>\n",
       "      <td>Burning House</td>\n",
       "      <td>\\n[Verse 1]\\nI had a dream about a burning hou...</td>\n",
       "      <td>[country]</td>\n",
       "      <td>[dream, burning, house, stuck, inside, get, la...</td>\n",
       "      <td>dream burning house stuck inside get laid besi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Johnny Cash</td>\n",
       "      <td>Folsom Prison Blues</td>\n",
       "      <td>I hear the train a-comin', it's rolling 'round...</td>\n",
       "      <td>[country]</td>\n",
       "      <td>[hear, train, acomin, rolling, round, bend, ai...</td>\n",
       "      <td>hear train acomin rolling round bend aint seen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                        title  \\\n",
       "0  Taylor Swift                       ​betty   \n",
       "1   John Denver  Take Me Home, Country Roads   \n",
       "2   Post Malone              Feeling Whitney   \n",
       "3           Cam                Burning House   \n",
       "4   Johnny Cash          Folsom Prison Blues   \n",
       "\n",
       "                                              lyrics      genre  \\\n",
       "0  Betty, I won't make assumptions\\nAbout why you...  [country]   \n",
       "1  Almost Heaven, West Virginia\\nBlue Ridge Mount...  [country]   \n",
       "2  I've been looking for someone...\\nOoh, ooh, oo...  [country]   \n",
       "3  \\n[Verse 1]\\nI had a dream about a burning hou...  [country]   \n",
       "4  I hear the train a-comin', it's rolling 'round...  [country]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [betty, make, assumptions, switched, homeroom,...   \n",
       "1  [almost, heaven, west, virginia, blue, ridge, ...   \n",
       "2  [looking, someone, ooh, ooh, ooh, ooh, ooh, oo...   \n",
       "3  [dream, burning, house, stuck, inside, get, la...   \n",
       "4  [hear, train, acomin, rolling, round, bend, ai...   \n",
       "\n",
       "                                        lyrics_clean  \n",
       "0  betty make assumptions switched homeroom think...  \n",
       "1  almost heaven west virginia blue ridge mountai...  \n",
       "2  looking someone ooh ooh ooh ooh ooh oohooh ooh...  \n",
       "3  dream burning house stuck inside get laid besi...  \n",
       "4  hear train acomin rolling round bend aint seen...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "# Read in preprocessed data\n",
    "preproc_df = pd.read_csv(\"data/genre_prepped.csv.gz\", compression = \"gzip\",\n",
    "                         converters = {\"tokens\": literal_eval, \"genre\" : literal_eval})\n",
    "\n",
    "# drop unnecessary columns (index and unnamed index columns)\n",
    "preproc_df = preproc_df.drop(preproc_df.columns[0:2], axis = 1)\n",
    "\n",
    "# Sample Table\n",
    "preproc_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert genres to set for multilabel encoding\n",
    "preproc_df[\"genre_set\"] = preproc_df[\"genre\"].map(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "genre_array = mlb.fit_transform(preproc_df[\"genre_set\"])\n",
    "genre_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label array to sparse matrix\n",
    "genre_sparse = sparse.csr_matrix(genre_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize text input\n",
    "We'll use TF-IDF vectors for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "text_sparse = tfidf_vectorizer.fit_transform(preproc_df['lyrics_clean'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into training and testing\n",
    "Using 70/30 train/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(text_sparse, genre_array,\n",
    "                                                    test_size= 0.3 , random_state= 2023)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models \n",
    "\n",
    "For classification, the selected models will demonstrate the commonly used for text classification: K-Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__estimator__metric': 'euclidean',\n",
       " 'knn__estimator__n_neighbors': 1,\n",
       " 'knn__estimator__weights': 'uniform'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up hyperparameter options\n",
    "n_neighbors = range(1,21, 2)\n",
    "weights = ['uniform', 'distance']\n",
    "metric = ['euclidean', 'minkowski'] # Manhattan was failing to fit - these two should work alright though\n",
    "\n",
    "# Setup model pipeline so we can reference it in param_distributions\n",
    "knn_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('knn', MultiOutputClassifier(KNeighborsClassifier(), n_jobs= - 1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Search\n",
    "knn_tuned = GridSearchCV(\n",
    "    estimator= knn_pipe,\n",
    "    param_grid = {'knn__estimator__n_neighbors' : n_neighbors,\n",
    "                   'knn__estimator__weights' : weights,\n",
    "                   'knn__estimator__metric' : metric}\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Return the best model parameters\n",
    "knn_tuned.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save so we don't need to retrain in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(knn_tuned, open('models/knn_tuned.sav', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Delete Later -\n",
    "It will probably be quicker without losing to much performance to run RandomizedSearchCV() for more complex models. Everything is the same as GridSearchCV() except param_grid needs to be param_distributions and you can set n_iter to control how many randomized hyperparameters to search through."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example Load\n",
    "knn_load = pickle.load(open('models/knn_tuned.sav', 'rb'))\n",
    "knn_load.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
